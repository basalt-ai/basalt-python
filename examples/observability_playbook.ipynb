{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Basalt Observability End-to-End Playbook\n",
    "\n",
    "This notebook demonstrates how to combine Basalt's observability helpers with common LLM flows, evaluators,\n",
    "experiment tagging, and Google AI Studio (Gemini) interactions. Each scenario demonstrates modern OpenTelemetry-based\n",
    "observability patterns with the Basalt SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Install the SDK in editable mode with dev extras: `uv pip install -e \".[dev]\"`\n",
    "- (Optional) Install the Google Generative AI SDK: `pip install google-generativeai`\n",
    "- Set the following environment variables before running the notebook:\n",
    "  - `BASALT_API_KEY` – your Basalt API key\n",
    "  - `GOOGLE_API_KEY` – Google AI Studio key (Gemini)\n",
    "  - `TRACELOOP_TRACE_CONTENT=1` if you want prompts/completions captured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from basalt import Basalt\n",
    "from basalt.observability import evaluate, observe, start_observe\n",
    "\n",
    "try:\n",
    "    from google import genai\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    genai = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## 1. Configure the Basalt client\n",
    "\n",
    "Initialize the Basalt client with telemetry configuration. Use `start_observe` to create root spans with identity and experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "\n",
    "from basalt import TelemetryConfig\n",
    "\n",
    "# Create telemetry configuration\n",
    "exporter = OTLPSpanExporter(endpoint=\"http://127.0.0.1:4317\", insecure=True)\n",
    "telemetry = TelemetryConfig(service_name=\"notebook\", exporter=exporter)\n",
    "\n",
    "# Initialize Basalt client\n",
    "basalt_client = Basalt(\n",
    "    api_key=os.getenv(\"BASALT_API_KEY\", \"not-set\"),\n",
    "    telemetry_config=telemetry,\n",
    ")\n",
    "\n",
    "basalt_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## 2. Decorator-driven LLM spans with identity and evaluators\n",
    "\n",
    "Use `@start_observe` as the root span decorator with identity tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@evaluate(slugs=[\"accuracy\", \"toxicity\"])\n",
    "def summarize_with_gemini(prompt: str, *, model: str = \"gemini-2.5-flash-lite\") -> str | None:\n",
    "    \"\"\"\n",
    "    Summarize text using Gemini with automatic tracing.\n",
    "\n",
    "    The @evaluate decorator attaches evaluators to the span.\n",
    "    \"\"\"\n",
    "    if genai is None:\n",
    "        raise RuntimeError(\"google-genai is not installed\")\n",
    "\n",
    "    client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\", \"fake-key\"))\n",
    "    response = client.models.generate_content(model=model, contents=prompt)\n",
    "    return response.text\n",
    "\n",
    "# Wrap the call in a root span with identity\n",
    "@start_observe(\n",
    "    name=\"notebook.workflow\",\n",
    "    identity={\n",
    "        \"organization\": {\"id\": \"123\", \"name\": \"ACME\"},\n",
    "        \"user\": {\"id\": \"456\", \"name\": \"John Doe\"}\n",
    "    },\n",
    "    experiment={\"id\": \"exp-observability\", \"name\": \"demo-agent\"},\n",
    "    metadata={\"environment\": \"notebook\", \"workspace\": \"demo\"}\n",
    ")\n",
    "def run_gemini_demo():\n",
    "    try:\n",
    "        return summarize_with_gemini(\"Summarize the benefits of synthetic monitoring.\")\n",
    "    except Exception as exc:\n",
    "        observe.fail(exc)\n",
    "        return {\"error\": str(exc)}\n",
    "\n",
    "gemini_result = run_gemini_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## 3. Manual spans for orchestrating workflow stages\n",
    "\n",
    "Use `start_observe` for the root workflow span, then nest `observe(kind=...)` for retrieval, tool, generation, and event spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "with start_observe(\n",
    "    name=\"workflow.rag\",\n",
    "    identity={\n",
    "        \"organization\": {\"id\": \"123\", \"name\": \"ACME\"},\n",
    "        \"user\": {\"id\": \"456\", \"name\": \"John Doe\"}\n",
    "    },\n",
    "    # Only attach the experiment id; descriptive fields moved to metadata\n",
    "    experiment={\"id\": \"exp-rag-001\"},\n",
    "    metadata={\n",
    "        \"feature\": \"support-bot\",\n",
    "        \"experiment.name\": \"support-bot\"\n",
    "    }\n",
    "):\n",
    "    # Set evaluators on root span\n",
    "    observe.evaluate(\"latency-budget\")\n",
    "    observe.input({\"query\": \"error connecting to database\"})\n",
    "\n",
    "    # Step 1: Retrieval span for vector database search\n",
    "    with observe(kind=\"retrieval\", name=\"workflow.rag.retrieve\") as ret_span:\n",
    "        ret_span.set_attribute(\"query\", \"database_error\")\n",
    "        ret_span.set_attribute(\"results_count\", 3)\n",
    "        ret_span.set_attribute(\"top_k\", 5)\n",
    "\n",
    "\n",
    "    # Step 2: Tool span for external tool call (e.g., web search)\n",
    "    with observe(kind=\"tool\", name=\"workflow.rag.tool\") as tool_span:\n",
    "        tool_span.set_attribute(\"tool_name\", \"web-search\")\n",
    "        tool_span.set_input({\"query\": \"database connection refused troubleshooting\"})\n",
    "        tool_span.set_output({\"summary\": \"Check credentials and firewall rules.\"})\n",
    "\n",
    "    # Step 3: LLM generation span for final answer\n",
    "    with observe(kind=\"generation\", name=\"workflow.rag.answer\") as llm_span:\n",
    "        llm_span.set_attribute(\"model\", \"gemini-1.5-flash\")\n",
    "        llm_span.set_attribute(\"prompt\", \"Provide mitigation steps\")\n",
    "        llm_span.set_attribute(\"completion\", \"1. Verify credentials...\")\n",
    "        llm_span.set_attribute(\"tokens_input\", 200)\n",
    "        llm_span.set_attribute(\"tokens_output\", 180)\n",
    "\n",
    "    # Step 4: Event span for workflow state tracking\n",
    "    with observe(kind=\"event\", name=\"workflow.rag.event\") as event_span:\n",
    "        event_span.set_attribute(\"event_type\", \"handoff\")\n",
    "        event_span.set_attribute(\"payload\", {\"team\": \"support\", \"status\": \"ready\"})\n",
    "\n",
    "    observe.output({\"status\": \"completed\", \"steps\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## 4. Dynamic experiment and metadata updates\n",
    "\n",
    "Use `observe.experiment()` to attach or override experiment metadata, and `observe.metadata()` to add custom attributes to the current span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with start_observe(\n",
    "    name=\"workflow.ab-test\",\n",
    "    identity={\n",
    "        \"organization\": {\"id\": \"123\", \"name\": \"ACME\"},\n",
    "        \"user\": {\"id\": \"456\", \"name\": \"John Doe\"}\n",
    "    },\n",
    "    # Keep only the experiment id; move name & feature slug to metadata\n",
    "    experiment={\"id\": \"exp-baseline\"},\n",
    "    metadata={\n",
    "        \"experiment.name\": \"baseline-playbook\",\n",
    "        \"feature.slug\": \"demo-agent\"\n",
    "    }\n",
    "):\n",
    "    # Override experiment dynamically (variant stored as attribute on override span)\n",
    "    observe.experiment(\"exp-variant\", variant=\"demo-agent-b\")\n",
    "\n",
    "    # Add evaluators and metadata\n",
    "    observe.evaluate(\"judge-hallucination\")\n",
    "\n",
    "    observe.metadata({\"latency_ms\": 245, \"variant_override\": True})\n",
    "    observe.output({\"status\": \"ab_test_complete\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "## 5. Shutdown and cleanup\n",
    "\n",
    "Flush telemetry buffers when the workflow completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basalt_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basalt-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
