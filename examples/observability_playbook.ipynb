{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Basalt Observability End-to-End Playbook\n",
    "\n",
    "This notebook demonstrates how to combine Basalt's observability helpers with common LLM flows, evaluators,\n",
    "experiment tagging, and Google AI Studio (Gemini) interactions. Each scenario demonstrates modern OpenTelemetry-based\n",
    "observability patterns with the Basalt SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Install the SDK in editable mode with dev extras: `uv pip install -e \".[dev]\"`\n",
    "- (Optional) Install the Google Generative AI SDK: `pip install google-generativeai`\n",
    "- Set the following environment variables before running the notebook:\n",
    "  - `BASALT_API_KEY` – your Basalt API key\n",
    "  - `GOOGLE_API_KEY` – Google AI Studio key (Gemini)\n",
    "  - `TRACELOOP_TRACE_CONTENT=1` if you want prompts/completions captured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from basalt import Basalt\n",
    "from basalt.observability import (\n",
    "    add_default_evaluators,\n",
    "    attach_trace_experiment,\n",
    "    configure_trace_defaults,\n",
    "    trace_event,\n",
    "    trace_generation,  # Modern naming (replaces trace_llm_call)\n",
    "    trace_retrieval,\n",
    "    trace_span,\n",
    "    trace_tool,\n",
    ")\n",
    "from basalt.observability.decorators import trace_generation as trace_generation_decorator\n",
    "\n",
    "try:\n",
    "    from google import genai\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    genai = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## 1. Configure the Basalt client and default trace context\n",
    "\n",
    "We prime global defaults so that every span carries user, organization, and evaluator metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure defaults before instantiating the client\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "\n",
    "from basalt import TelemetryConfig\n",
    "\n",
    "configure_trace_defaults(\n",
    "    user={\"id\": \"user-notebook\", \"name\": \"Analyst\"},\n",
    "    organization={\"id\": \"org-research\", \"name\": \"Basalt Research\"},\n",
    "    metadata={\"environment\": \"notebook\", \"workspace\": \"demo\"},\n",
    "    evaluators=[\"accuracy\"],\n",
    ")\n",
    "# add_default_evaluators takes *args, so pass as a positional argument\n",
    "add_default_evaluators(\"toxicity\")\n",
    "\n",
    "exporter = OTLPSpanExporter(endpoint=\"http://127.0.0.1:4317\", insecure=True)\n",
    "telemetry = TelemetryConfig(service_name=\"notebook\", exporter=exporter)\n",
    "\n",
    "basalt_client = Basalt(\n",
    "    api_key=os.getenv(\"BASALT_API_KEY\", \"not-set\"),\n",
    "    trace_experiment={\"id\": \"exp-observability\", \"feature_slug\": \"demo-agent\"},\n",
    "    trace_metadata={\"notebook\": \"observability-playbook\"},\n",
    "    telemetry_config=telemetry,\n",
    ")\n",
    "\n",
    "basalt_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## 2. Decorator-driven LLM spans with evaluators\n",
    "\n",
    "The `@trace_generation` decorator automatically captures prompts, completions, and token usage for LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_generation_decorator(name=\"notebook.gemini.summarize\")\n",
    "def summarize_with_gemini(prompt: str, *, model: str = \"gemini-2.5-flash-lite\") -> str | None:\n",
    "    \"\"\"\n",
    "    Summarize text using Gemini with automatic tracing.\n",
    "\n",
    "    The @trace_generation decorator creates an LLM span and captures:\n",
    "    - The prompt text\n",
    "    - The completion/response\n",
    "    - Model information\n",
    "    - Token usage (if available)\n",
    "    \"\"\"\n",
    "    if genai is None:\n",
    "        raise RuntimeError(\"google-genai is not installed\")\n",
    "\n",
    "    client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\", \"fake-key\"))\n",
    "    response = client.models.generate_content(model=model, contents=prompt)\n",
    "    # Convert response to dict so the decorator can introspect usage\n",
    "    return response.text\n",
    "\n",
    "try:\n",
    "    gemini_result = summarize_with_gemini(\"Summarize the benefits of synthetic monitoring.\")\n",
    "except Exception as exc:\n",
    "    gemini_result = {\"error\": str(exc)}\n",
    "\n",
    "gemini_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## 3. Manual spans for orchestrating workflow stages\n",
    "\n",
    "We combine `trace_span`, `trace_tool`, and `trace_event` to follow a retrieval-augmented generation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace_span(\"workflow.rag\", attributes={\"feature\": \"support-bot\"}) as span:\n",
    "    span.add_evaluator(\"latency-budget\")\n",
    "    span.set_experiment(\"exp-rag-001\", feature_slug=\"support-bot\")\n",
    "\n",
    "    # Step 1: Retrieval span for vector database search\n",
    "    with trace_retrieval(\"workflow.rag.retrieve\") as ret_span:\n",
    "        ret_span.set_query(\"error connecting to database\")\n",
    "        ret_span.set_results_count(3)\n",
    "        ret_span.set_top_k(5)\n",
    "\n",
    "    # Step 2: Tool span for external tool call (e.g., web search)\n",
    "    with trace_tool(\"workflow.rag.tool\") as tool_span:\n",
    "        tool_span.set_tool_name(\"web-search\")\n",
    "        tool_span.set_input({\"query\": \"database connection refused troubleshooting\"})\n",
    "        tool_span.set_output({\"summary\": \"Check credentials and firewall rules.\"})\n",
    "\n",
    "    # Step 3: LLM generation span for final answer\n",
    "    with trace_generation(\"workflow.rag.answer\") as llm_span:\n",
    "        llm_span.set_model(\"gemini-1.5-flash\")\n",
    "        llm_span.set_prompt(\"Provide mitigation steps\")\n",
    "        llm_span.set_completion(\"1. Verify credentials...\")\n",
    "        llm_span.set_tokens(input=200, output=180)\n",
    "\n",
    "    # Step 4: Event span for workflow state tracking\n",
    "    with trace_event(\"workflow.rag.event\") as event_span:\n",
    "        event_span.set_event_type(\"handoff\")\n",
    "        event_span.set_payload({\"team\": \"support\", \"status\": \"ready\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## 4. Experiments and trace enrichment APIs\n",
    "\n",
    "Attach experiment metadata globally, then override within the active span when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attach_trace_experiment(\"exp-baseline\", name=\"baseline-playbook\", feature_slug=\"demo-agent\")\n",
    "\n",
    "with trace_span(\"workflow.ab-test\") as span:\n",
    "    span.set_experiment(\"exp-variant\", name=\"variant-b\", feature_slug=\"demo-agent-b\")\n",
    "    span.add_evaluator(\"judge-hallucination\")\n",
    "    # Use timezone-aware datetime (modern best practice)\n",
    "    span.add_event(\"scoring_started\", {\"timestamp\": datetime.now(timezone.utc).isoformat()})\n",
    "    span.set_attribute(\"basalt.metric.latency_ms\", 245)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "## 5. Shutdown and cleanup\n",
    "\n",
    "Flush telemetry buffers when the workflow completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basalt_client.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basalt-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}