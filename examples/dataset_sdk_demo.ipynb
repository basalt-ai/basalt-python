{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basalt Dataset SDK Demo\n",
    "\n",
    "This notebook demonstrates how to use the Basalt Dataset SDK to interact with your Basalt datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  # Needed to make notebook work in VSCode\n",
    "\n",
    "os.environ[\"BASALT_BUILD\"] = \"development\"\n",
    "\n",
    "from basalt import Basalt\n",
    "\n",
    "# Initialize the SDK\n",
    "basalt = Basalt(\n",
    "    api_key=\"sk-...\",  # Replace with your API key\n",
    "    log_level=\"debug\"  # Optional: Set log level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Listing Available Datasets\n",
    "\n",
    "Retrieve all datasets available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all datasets in the workspace\n",
    "err, datasets = basalt.datasets.list()\n",
    "\n",
    "if err:\n",
    "    print(f\"Error listing datasets: {err}\")\n",
    "else:\n",
    "    print(f\"Found {len(datasets)} datasets:\")\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        print(f\"{i+1}. {dataset.name} (slug: {dataset.slug})\")\n",
    "        print(f\"   - Description: {dataset.description if dataset.description else 'No description'}\")\n",
    "        print(f\"   - Columns: {', '.join(dataset.columns)}\")\n",
    "    \n",
    "    # Store the first dataset slug for later use (if available)\n",
    "    first_dataset_slug = datasets[0].slug if datasets else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting a Specific Dataset\n",
    "\n",
    "Retrieve details for a specific dataset using its slug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first dataset from the list or replace with a specific slug\n",
    "dataset_slug = first_dataset_slug if 'first_dataset_slug' in locals() and first_dataset_slug else \"your-dataset-slug\"\n",
    "\n",
    "err, dataset = basalt.datasets.get(dataset_slug)\n",
    "\n",
    "if err:\n",
    "    print(f\"Error getting dataset: {err}\")\n",
    "else:\n",
    "    print(f\"Dataset details for '{dataset.name}'\")\n",
    "    print(f\"Slug: {dataset.slug}\")\n",
    "    print(f\"Description: {dataset.description if dataset.description else 'No description'}\")\n",
    "    print(f\"Columns: {', '.join(dataset.columns)}\")\n",
    "    print(f\"Number of rows: {len(dataset.rows)}\")\n",
    "    \n",
    "    if dataset.rows:\n",
    "        print(\"\\nSample rows:\")\n",
    "        for i, row in enumerate(dataset.rows[:3]):  # Show up to 3 rows\n",
    "            print(f\"Row {i+1}:\")\n",
    "            print(f\"  Values: {row.values}\")\n",
    "            if row.name:\n",
    "                print(f\"  Name: {row.name}\")\n",
    "            if row.idealOutput:\n",
    "                print(f\"  Ideal output: {row.idealOutput}\")\n",
    "            if row.metadata:\n",
    "                print(f\"  Metadata: {row.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding a Row to a Dataset\n",
    "\n",
    "Create a new row (item) in an existing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataset from the previous example\n",
    "if 'dataset' in locals() and dataset:\n",
    "    # Build values for all columns in the dataset\n",
    "    values = {}\n",
    "    for column in dataset.columns:\n",
    "        values[column] = f\"Example value for {column} - {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    \n",
    "    # Create the row\n",
    "    err, row, warning = basalt.datasets.addRow(\n",
    "        slug=dataset.slug,\n",
    "        values=values,\n",
    "        name=\"Notebook Example Row\",\n",
    "        ideal_output=\"This is an ideal output for this row\",\n",
    "        metadata={\"source\": \"Jupyter notebook example\", \"timestamp\": __import__('datetime').datetime.now().isoformat()}\n",
    "    )\n",
    "    \n",
    "    if err:\n",
    "        print(f\"Error creating dataset row: {err}\")\n",
    "    else:\n",
    "        print(\"Successfully created new dataset row:\")\n",
    "        print(f\"Values: {row.values}\")\n",
    "        print(f\"Name: {row.name}\")\n",
    "        print(f\"Ideal output: {row.idealOutput}\")\n",
    "        print(f\"Metadata: {row.metadata}\")\n",
    "        \n",
    "        if warning:\n",
    "            print(f\"Warning: {warning}\")\n",
    "else:\n",
    "    print(\"Please run the previous cell to get a dataset first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error Handling with Dataset SDK\n",
    "\n",
    "Demonstrate proper error handling when working with datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safely_add_dataset_row(slug, values, name=None, ideal_output=None, metadata=None):\n",
    "    \"\"\"Safely add a row to a dataset with robust error handling\"\"\"\n",
    "    try:\n",
    "        err, row, warning = basalt.datasets.addRow(\n",
    "            slug=slug,\n",
    "            values=values,\n",
    "            name=name,\n",
    "            ideal_output=ideal_output,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "        if err:\n",
    "            print(f\"Error creating dataset row: {err}\")\n",
    "            return None\n",
    "            \n",
    "        if warning:\n",
    "            print(f\"Warning: {warning}\")\n",
    "            \n",
    "        return row\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test with a valid dataset\n",
    "if 'dataset_slug' in locals() and dataset_slug:\n",
    "    values = {\"input\": \"Test input\", \"output\": \"Test output\"}\n",
    "    row = safely_add_dataset_row(dataset_slug, values, name=\"Error Handling Test\")\n",
    "    \n",
    "    if row:\n",
    "        print(f\"Successfully created row: {row.name}\")\n",
    "\n",
    "# Test with an invalid dataset slug\n",
    "print(\"\\nTesting with invalid dataset slug:\")\n",
    "invalid_row = safely_add_dataset_row(\"non-existent-dataset\", {\"input\": \"Test input\"})\n",
    "print(f\"Result with invalid slug: {invalid_row}\")\n",
    "\n",
    "# Test with missing required values\n",
    "if 'dataset' in locals() and dataset and len(dataset.columns) > 0:\n",
    "    print(\"\\nTesting with missing required values:\")\n",
    "    # Deliberately create incomplete values dict\n",
    "    incomplete_values = {column: \"value\" for column in list(dataset.columns)[1:]} if len(dataset.columns) > 1 else {}\n",
    "    incomplete_row = safely_add_dataset_row(dataset.slug, incomplete_values)\n",
    "    print(f\"Result with incomplete values: {incomplete_row}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
